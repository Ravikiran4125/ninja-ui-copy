```bolt
You are an AI assistant contributing to a TypeScript monorepo focused on building a powerful, modular **agentic AI workflow builder**. This is more than just an agent framework — it’s a full-stack platform for turning **voice or chat-based brainstorming** into visual, composable, deployable AI agents.

---

## 🧠 Big Picture

The final product consists of:

- A **UI-driven app** that enables users to:
  - Chat or speak ideas
  - Convert ideas into AI workflows
  - Edit flows via drag-drop interface
  - Deploy agents

- A backend **agent orchestration package** called `ninja-agents` that powers all AI reasoning, skills, tools, and chaining.

---

## 📦 `packages/ninja-agents/` — Agent Engine

### Purpose:
Composable AI Agent Framework. Used to define:

- **🌀 Shuriken**: Small, validated, atomic tools (functions, API calls)
- **🥋 Kata**: Skills/tasks that use Shuriken and embed business logic
- **🥷 Shinobi**: Agents that orchestrate Kata with memory and reasoning
- **🎼 Orchestration**: Compose full workflows of Shinobi and Kata
- **🧠 Memory**: Store and retrieve context or results

This is a reusable library — NOT the UI.

### Structure (recommendation):
```
ninja-agents/
  shuriken/        → atomic tools
  katas/           → skills using tools
  shinobi/         → full agents (memory, reasoning)
  orchestrations/  → composed agent workflows
  api/             → orchestration endpoints
```

### Example Usage:
```ts
import { Shuriken, Kata, Shinobi } from 'ninja-agents';
```

Refer to the [package README](ninja-ui/packages/ninja-agents/README.md) for:
- How to define a tool (shuriken)
- How to compose skills (kata)
- How to build agents (shinobi)
- How to orchestrate and deploy flows

⚠️ **Do not edit package files arbitrarily**. Understand the role of each abstraction before modifying. Only update with awareness of how it impacts UI/app integration.

---

## 🌐 `web/` — Voice+Visual App

### Purpose:
Frontend application for:

- User brainstorming (chat/voice)
- Flow visualization (wireflow UI)
- Editing + deploying agent workflows

### Expected UI Features:
- Visual flow editor (drag/drop Kata and Shuriken)
- Agent chat interface (to define flow interactively)
- Voice interaction + speech-to-intent mapping
- Real-time preview and deployment

### Folder Hints:
```
web/
  components/
    shared/        → UI elements (Card, Button)
    kata/          → UI for Kata config
    shuriken/      → UI for tool config
  hooks/           → e.g. useAgentBuilder
  stores/          → Zustand for UI states
```

### UI Stack:
- React + TypeScript
- TailwindCSS + shadcn/ui
- `lucide-react` for icons
- Framer Motion for animation

---

## 🧭 Prompting & Evaluation Guidelines

While implementing features:

- 🔄 Ask: _Does this move us from voice/chat → agent → visual wireflow → deployable unit?_
- 🧩 Be modular: Define every Shuriken, Kata, Shinobi in its own file
- 🧪 Testable: Each unit should be testable in isolation
- 🔍 Describe your intention: e.g. _“Adding this Shuriken so users can fetch stock prices in their agents”_

---

## ⚠️ Rules of Contribution

- Never break exports: use `core/index.ts` or `web/hooks/...` as boundaries
- No logic duplication across app + package
- All function/tool names must follow naming rules (`a-zA-Z0-9_-`)
- If unsure: refer to `ninja-agents` README before editing anything

---

## ✍️ Bolt Prompts Should Help With:

- Suggesting tool (Shuriken) structure
- Breaking down large agents into skills (Kata)
- Visualizing orchestration logic
- Translating voice inputs into deployable agent config
- Avoiding tight coupling between package + app

---

## ✅ Example Progress Prompting

When you're building a feature, consider including:

> "This feature moves us closer to converting brainstorming sessions into agent orchestration flows."

> "This update helps users visualize how a Shinobi agent will function across multiple skills."

> "Adding this Kata allows chaining Shuriken for X domain logic."

---

Stay lean, stay modular, and always keep the end-user flow in mind: **“brainstorm → visualize → deploy.”**
```